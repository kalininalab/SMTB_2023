{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3089086-5a6d-468c-a2b5-5630c4a2a147",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from captum.attr import IntegratedGradients, DeepLift, GradientShap, NoiseTunnel, FeatureAblation\n",
    "import plotly.express as px\n",
    "import wandb\n",
    "from src.esm_embedder import ESMEmbedder\n",
    "from pytorch_lightning import seed_everything\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4521578",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = wandb.Api()\n",
    "current_run = wandb.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3cf511-806c-449a-be22-3a217dbf5413",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim: int):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.LazyLinear(1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf728ab-a61a-47f7-8dfe-a79f3bf629a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dims = {\n",
    "    \"esm2_t33_650M_UR50D\": 1280,\n",
    "    \"esm2_t30_150M_UR50D\": 640,\n",
    "    \"esm2_t12_35M_UR50D\": 480,\n",
    "    \"esm2_t6_8M_UR50D\": 320,\n",
    "}\n",
    "model_names = {\n",
    "    33: \"esm2_t33_650M_UR50D\",\n",
    "    30: \"esm2_t30_150M_UR50D\",\n",
    "    12: \"esm2_t12_35M_UR50D\",\n",
    "    6: \"esm2_t6_8M_UR50D\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5429449-c938-45ac-bbda-370cbd4b4ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_baseline(num_layers: int, current_layer: int):\n",
    "    data = [(\"prot1\", \"\")]\n",
    "    embedder = ESMEmbedder(num_layers)\n",
    "    reprs = embedder.run(data)[0][\"representations\"]\n",
    "    return torch.stack([reprs[x].squeeze(0).mean(0) for x in range(num_layers + 1)])[current_layer]\n",
    "\n",
    "\n",
    "def get_data(dataset: str, num_layers: str, current_layer: int, num_samples: int = 4):\n",
    "    p = Path(\"/shared\") / dataset / model_names[num_layers] / \"test\"\n",
    "    assert p.exists()\n",
    "    embeddings = []\n",
    "    print(p)\n",
    "    fluorescence_values = {}\n",
    "    for idx, i in enumerate(p.glob(\"*.pt\")):\n",
    "        fluorescence_values[str(i)] = float(i.stem.split(\"|\")[-1])\n",
    "    fluorescence_values = pd.Series(fluorescence_values).sort_values()\n",
    "    fluorescence_values = fluorescence_values.index.to_list()\n",
    "    for idx, i in enumerate(fluorescence_values[: num_samples // 2] + fluorescence_values[-num_samples // 2 :]):\n",
    "        t = torch.load(i)\n",
    "        emb = torch.stack([t[\"mean_representations\"][x] for x in range(num_layers + 1)])\n",
    "        embeddings.append(emb)\n",
    "    return torch.stack(embeddings)[:, current_layer, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252c12e4-af99-428e-80ea-6c4013aad7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ds_name in [\"stability\", \"fluorescence\"]:\n",
    "    runs = api.runs(f\"smtb2023/{ds_name}\")\n",
    "\n",
    "    run_attributions = []\n",
    "\n",
    "    for model_run in runs:\n",
    "        if model_run.state != \"finished\":\n",
    "            continue\n",
    "        run_id = model_run.id\n",
    "        model_name = model_run.config[\"model_name\"]\n",
    "        # if model_name != \"esm2_t6_8M_UR50D\":\n",
    "        #     continue\n",
    "        model_layer = model_run.config[\"layer_num\"]\n",
    "        total_num_layers = int(model_name.split(\"_\")[1][1:])\n",
    "        data = get_data(ds_name, total_num_layers, model_layer)\n",
    "        baseline = get_baseline(total_num_layers, model_layer)\n",
    "        baseline = torch.stack([baseline] * data.size(0))\n",
    "        artifact = current_run.use_artifact(f\"smtb2023/{ds_name}/model-{run_id}:v0\", type=\"model\")\n",
    "        artifact_dir = artifact.download()\n",
    "        model = Model.load_from_checkpoint(\n",
    "            f\"artifacts/model-{run_id}:v0/model.ckpt\", input_dim=input_dims[model_name], hidden_dim=512\n",
    "        )\n",
    "        model.eval()\n",
    "        model = model.cuda()\n",
    "        data = data.cuda()\n",
    "        baseline = baseline.cuda()\n",
    "\n",
    "        ig = IntegratedGradients(model)\n",
    "        ig_nt = NoiseTunnel(ig)\n",
    "        dl = DeepLift(model)\n",
    "        gs = GradientShap(model)\n",
    "        fa = FeatureAblation(model)\n",
    "\n",
    "        ig_attr = ig.attribute(data, baselines=baseline, n_steps=50)\n",
    "        ig_nt_attr = ig_nt.attribute(data, baselines=baseline)\n",
    "        dl_attr = dl.attribute(data, baselines=baseline)\n",
    "        # gs_attr = gs.attribute(data, baselines=baseline, X_train)\n",
    "        fa_attr = fa.attribute(data, baselines=baseline)\n",
    "        run_attributions.append(\n",
    "            {\n",
    "                \"model_name\": model_name,\n",
    "                \"layer\": model_layer,\n",
    "                \"run_id\": run_id,\n",
    "                \"ig_attr\": ig_attr.mean(0).cpu(),\n",
    "                \"ig_nt_attr\": ig_nt_attr.mean(0).cpu(),\n",
    "                \"dl_attr\": dl_attr.mean(0).cpu(),\n",
    "                # \"gs_attr\": gs_attr.mean(0).cpu(),\n",
    "                \"fa_attr\": fa_attr.mean(0).cpu(),\n",
    "                \"data\": data.cpu(),\n",
    "            }\n",
    "        )\n",
    "    with open(f\"{ds_name}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(run_attributions, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
