{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3089086-5a6d-468c-a2b5-5630c4a2a147",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from captum.attr import IntegratedGradients\n",
    "import plotly.express as px\n",
    "import wandb\n",
    "from src.esm_embedder import ESMEmbedder\n",
    "from pytorch_lightning import seed_everything\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4521578",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = wandb.Api()\n",
    "current_run = wandb.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3cf511-806c-449a-be22-3a217dbf5413",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim: int):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.LazyLinear(1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf728ab-a61a-47f7-8dfe-a79f3bf629a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dims = {\n",
    "    \"esm2_t33_650M_UR50D\": 1280,\n",
    "    \"esm2_t30_150M_UR50D\": 640,\n",
    "    \"esm2_t12_35M_UR50D\": 480,\n",
    "    \"esm2_t6_8M_UR50D\": 320,\n",
    "}\n",
    "model_names = {\n",
    "    33: \"esm2_t33_650M_UR50D\",\n",
    "    30: \"esm2_t30_150M_UR50D\",\n",
    "    12: \"esm2_t12_35M_UR50D\",\n",
    "    6: \"esm2_t6_8M_UR50D\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5429449-c938-45ac-bbda-370cbd4b4ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_baseline(num_layers: int, current_layer: int):\n",
    "    data = [(\"prot1\", \"\")]\n",
    "    embedder = ESMEmbedder(num_layers)\n",
    "    reprs = embedder.run(data)[0][\"representations\"]\n",
    "    return torch.stack([reprs[x].squeeze(0).mean(0) for x in range(num_layers + 1)])[current_layer]\n",
    "\n",
    "\n",
    "def get_data(dataset: str, num_layers: str, current_layer: int, num_samples: int = 4):\n",
    "    p = Path(\"/shared\") / dataset / model_names[num_layers] / \"test\"\n",
    "    assert p.exists()\n",
    "    embeddings = []\n",
    "    print(p)\n",
    "    fluorescence_values = {}\n",
    "    for idx, i in enumerate(p.glob(\"*.pt\")):\n",
    "        fluorescence_values[str(i)] = float(i.stem.split(\"|\")[-1])\n",
    "    fluorescence_values = pd.Series(fluorescence_values).sort_values()\n",
    "    fluorescence_values = fluorescence_values.index.to_list()\n",
    "    for idx, i in enumerate(fluorescence_values[: num_samples // 2] + fluorescence_values[-num_samples // 2 :]):\n",
    "        t = torch.load(i)\n",
    "        emb = torch.stack([t[\"mean_representations\"][x] for x in range(num_layers + 1)])\n",
    "        embeddings.append(emb)\n",
    "    return torch.stack(embeddings)[:, current_layer, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252c12e4-af99-428e-80ea-6c4013aad7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_name = \"fluorescence\"\n",
    "runs = api.runs(f\"smtb2023/{ds_name}\")\n",
    "\n",
    "run_attributions = []\n",
    "\n",
    "\n",
    "for model_run in runs:\n",
    "    if model_run.state != \"finished\":\n",
    "        continue\n",
    "    run_id = model_run.id\n",
    "    model_name = model_run.config[\"model_name\"]\n",
    "    model_layer = model_run.config[\"layer_num\"]\n",
    "    total_num_layers = int(model_name.split(\"_\")[1][1:])\n",
    "    data = get_data(ds_name, total_num_layers, model_layer)\n",
    "    baseline = get_baseline(total_num_layers, model_layer)\n",
    "    baseline = torch.stack([baseline] * data.size(0))\n",
    "    artifact = current_run.use_artifact(f\"smtb2023/fluorescence/model-{run_id}:v0\", type=\"model\")\n",
    "    artifact_dir = artifact.download()\n",
    "    model = Model.load_from_checkpoint(\n",
    "        f\"artifacts/model-{run_id}:v0/model.ckpt\", input_dim=input_dims[model_name], hidden_dim=512\n",
    "    )\n",
    "    model.eval()\n",
    "\n",
    "    ig = IntegratedGradients(model.cuda())\n",
    "    attributions, delta = ig.attribute(data.cuda(), baseline.cuda(), return_convergence_delta=True)\n",
    "    run_attributions.append(\n",
    "        {\n",
    "            \"model_name\": model_name,\n",
    "            \"layer\": model_layer,\n",
    "            \"run_id\": run_id,\n",
    "            \"attributions\": attributions.mean(0).cpu(),\n",
    "            \"delta\": delta.cpu(),\n",
    "            \"data\": data.cpu(),\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4675f0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_attributions[0]['delta'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7924a870",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_runs = defaultdict(list)\n",
    "for run in run_attributions:\n",
    "    agg_runs[run[\"layer\"]].append(run['attributions'])\n",
    "agg_runs = {k:torch.stack(v) for k,v in agg_runs.items()}\n",
    "agg_runs = torch.stack([v.mean(0) for k,v in agg_runs.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c17767",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(tensor, dim:int):\n",
    "    return (tensor - tensor.min(dim=dim)[0]) / (tensor.max(dim=dim)[0] - tensor.min(dim=dim)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbcf7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.imshow(agg_runs.mean(1), aspect=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e084cec8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
